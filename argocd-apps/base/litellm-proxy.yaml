apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: litellm-proxy
  namespace: argocd
spec:
  project: default
  source:
    chart: litellm-helm
    repoURL: ghcr.io/berriai
    targetRevision: 0.1.812
    helm:
      valuesObject:
        ingress:
          enabled: true
          className: "nginx"
          hosts:
            - host: "llmproxy.echobase.network"
        proxy_config:
          model_list:
            - model_name: "gemma3:27b-it-qat"
              litellm_params:
                model: "ollama/gemma3:27b-it-qat"
                api_base: "http://r2d2.echobase.network:11434"
        service:
          type: LoadBalancer
      releaseName: litellm-proxy
  destination:
    server: https://kubernetes.default.svc
    namespace: litellm
  syncPolicy:
    syncOptions:
      - CreateNamespace=true
    automated:
      prune: true
      selfHeal: true
